{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba07c45c-ffdf-4586-ad66-1e84f5061670",
   "metadata": {},
   "source": [
    "# Amazon Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832edb3-836b-4933-8d6a-43717446ea7b",
   "metadata": {},
   "source": [
    "## Imports & Readings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93263e48-de4c-4e2b-b868-0a79339227f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/paulbojan/Documents/TU Wien/2.Semester/Machine Learning/assignments/ex1/local'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731afc77-1558-42d9-8065-774b89c2da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_train = pd.read_csv('datasets/review_train.csv')\n",
    "amazon_test = pd.read_csv('datasets/review_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12a2c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 10002)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V9992</th>\n",
       "      <th>V9993</th>\n",
       "      <th>V9994</th>\n",
       "      <th>V9995</th>\n",
       "      <th>V9996</th>\n",
       "      <th>V9997</th>\n",
       "      <th>V9998</th>\n",
       "      <th>V9999</th>\n",
       "      <th>V10000</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Shea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Riley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chachra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Agresti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nigam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9992  V9993  V9994  V9995  \\\n",
       "0   0  17   4   8   8   9   4   0   2   3  ...      0      0      0      0   \n",
       "1   1  21   9   5   8   6   2  16   3  12  ...      0      0      0      2   \n",
       "2   2   9   7   6   3   8   2   9   4   4  ...      0      0      0      0   \n",
       "3   3   8   3   5   2   4   3   8   2   4  ...      0      0      1      0   \n",
       "4   4  15   8   8   4   7   8   4   7   1  ...      0      0      0      0   \n",
       "\n",
       "   V9996  V9997  V9998  V9999  V10000    Class  \n",
       "0      0      0      0      1       1     Shea  \n",
       "1      2      1      0      1       0    Riley  \n",
       "2      0      0      0      1       1  Chachra  \n",
       "3      1      0      0      0       0  Agresti  \n",
       "4      0      0      0      0       0    Nigam  \n",
       "\n",
       "[5 rows x 10002 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display(amazon_train)\n",
    "print(amazon_train.shape)\n",
    "\n",
    "amazon_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a632da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 10001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V9991</th>\n",
       "      <th>V9992</th>\n",
       "      <th>V9993</th>\n",
       "      <th>V9994</th>\n",
       "      <th>V9995</th>\n",
       "      <th>V9996</th>\n",
       "      <th>V9997</th>\n",
       "      <th>V9998</th>\n",
       "      <th>V9999</th>\n",
       "      <th>V10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>751</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>753</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>754</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  V1  V2  V3  V4  V5  V6  V7  V8  V9  ...  V9991  V9992  V9993  V9994  \\\n",
       "0  750  23   6   4   7  11   0   5   2   6  ...      0      0      1      0   \n",
       "1  751  20  12  15   6   9  14   2   6   2  ...      1      3      0      0   \n",
       "2  752  13  10  10   5  12   5   3   4   5  ...      1      0      1      0   \n",
       "3  753  14  15   6   1   7   2   7   2   5  ...      0      0      1      2   \n",
       "4  754   9   8   3   4  10   3   2   2   1  ...      0      0      0      0   \n",
       "\n",
       "   V9995  V9996  V9997  V9998  V9999  V10000  \n",
       "0      0      0      0      0      0       0  \n",
       "1      0      0      0      0      0       0  \n",
       "2      0      0      1      0      1       1  \n",
       "3      0      2      1      0      1       0  \n",
       "4      0      0      0      0      1       0  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(amazon_test.shape)\n",
    "\n",
    "amazon_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c8fc6a-ae55-4e48-bc04-d70b236692e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ID'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m amazon_train\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m amazon_train\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ID'] not found in axis\""
     ]
    }
   ],
   "source": [
    "amazon_train.drop(['ID'], axis=1, inplace=True)\n",
    "amazon_train.isna().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b1e91-500d-48e4-88f5-ccd9784b8985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3359d-5fe4-4b15-a765-ca6b436a2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f6e1312-44ab-4073-a29f-99dff4b72fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shea', 'Riley', 'Chachra', 'Agresti', 'Nigam', 'Messick', 'Cutey',\n",
       "       'Mitchell', 'Ashbacher', 'Brody', 'Vernon', 'Goonan', 'Harp',\n",
       "       'Lovitt', 'Corn', 'Engineer', 'Calvinnme', 'Chell', 'Comdet',\n",
       "       'Kolln', 'Peterson', 'Dent', 'Wilson', 'Mark', 'Grove', 'Janson',\n",
       "       'Brown', 'Auken', 'Sherwin', 'Cholette', 'McKee', 'Taylor',\n",
       "       'Walters', 'Merritt', 'Blankenship', 'Chandler', 'Johnson',\n",
       "       'Hayes', 'Koenig', 'CFH', 'Lawyeraau', 'Davisson', 'Mahlers2nd',\n",
       "       'Power', 'Robert', 'Morrison', 'Lee', 'Neal', 'Bukowsky', 'Vision'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_train['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0060027-a779-41d2-9442-7fddc99eef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def perform_pca(data, n_components):\n",
    "    # Create PCA object with the desired number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    # Fit the PCA model to the data\n",
    "    pca.fit(data)\n",
    "    \n",
    "    # Transform the data to the reduced dimensionality\n",
    "    transformed_data = pca.transform(data)\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "\n",
    "\n",
    "# Perform PCA on the training data\n",
    "X_train_pca = perform_pca(X_train, n_components=2)\n",
    "X_train_pca = pd.DataFrame(X_train_pca, columns=['PC1', 'PC2'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0218f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a08031b5",
   "metadata": {},
   "source": [
    "## Approach Ideas:\n",
    "\n",
    "PCA -> Sparse PCA!\n",
    "\n",
    "LDA, QDA, RDA\n",
    "\n",
    "multinomial logistic regression\n",
    "\n",
    "\n",
    "We will try the Sparse PCA first. It seems promising!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5b6881f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5910, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def column_with_zero(df, threshold = 95):\n",
    "    results = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        coun_zero = (df[col] == 0).sum()\n",
    "        number_cols = len(df[\"Class\"])\n",
    "\n",
    "        percent_zero = (coun_zero / number_cols) * 100\n",
    "        if percent_zero >= threshold:\n",
    "            results.append({'Column Name': col, 'Percentage': percent_zero})\n",
    " \n",
    "    result_df = pd.DataFrame(results)\n",
    "    return result_df\n",
    "\n",
    "df_temp = column_with_zero(amazon_train)\n",
    "\n",
    "# PLot distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(df_temp['Percentage'], bins=90, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of the percentages of zeros in the columns')\n",
    "plt.xlabel(' percentages of zeros')\n",
    "plt.ylabel('Number of columns')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_temp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f540876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V9992</th>\n",
       "      <th>V9993</th>\n",
       "      <th>V9994</th>\n",
       "      <th>V9995</th>\n",
       "      <th>V9996</th>\n",
       "      <th>V9997</th>\n",
       "      <th>V9998</th>\n",
       "      <th>V9999</th>\n",
       "      <th>V10000</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Shea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Riley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chachra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Agresti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nigam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2  V3  V4  V5  V6  V7  V8  V9  V10  ...  V9992  V9993  V9994  V9995  \\\n",
       "0  17   4   8   8   9   4   0   2   3    5  ...      0      0      0      0   \n",
       "1  21   9   5   8   6   2  16   3  12    6  ...      0      0      0      2   \n",
       "2   9   7   6   3   8   2   9   4   4    5  ...      0      0      0      0   \n",
       "3   8   3   5   2   4   3   8   2   4    4  ...      0      0      1      0   \n",
       "4  15   8   8   4   7   8   4   7   1    3  ...      0      0      0      0   \n",
       "\n",
       "   V9996  V9997  V9998  V9999  V10000    Class  \n",
       "0      0      0      0      1       1     Shea  \n",
       "1      2      1      0      1       0    Riley  \n",
       "2      0      0      0      1       1  Chachra  \n",
       "3      1      0      0      0       0  Agresti  \n",
       "4      0      0      0      0       0    Nigam  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "afdb4692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Component_1  Component_2  Component_3  Component_4  Component_5    Class\n",
      "0   -18.728565    -2.020127    10.247295   -16.669304    23.554972     Shea\n",
      "1    23.806106    41.796214   105.134683    -3.771703     1.172454    Riley\n",
      "2   -57.908152    25.075320   -15.436117    -9.729442   -23.956176  Chachra\n",
      "3   -25.967377    15.462059   -14.965175   -20.436362     7.077724  Agresti\n",
      "4   -12.056590    15.961342    13.649013    30.253384    43.836749    Nigam\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "X = amazon_train.drop('Class', axis=1)  \n",
    "y = amazon_train['Class']  \n",
    "\n",
    "# number of components\n",
    "n_components = 5\n",
    "\n",
    "sparse_pca = SparsePCA(n_components=n_components, random_state=111)\n",
    "\n",
    "#fit the model\n",
    "transformed_data = sparse_pca.fit_transform(X)\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=[f'Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "#Add target variable back \n",
    "transformed_df['Class'] = y\n",
    "\n",
    "print(transformed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f658f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01834db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Component_1  Component_2  Component_3  Component_4  Component_5  \\\n",
      "0     3.771538     4.252988    -7.817311    10.002530    18.163779   \n",
      "1  -126.142791    48.983971   -52.803613     2.483441    -1.148807   \n",
      "2    77.670115    29.780364     4.925803    -3.529896    -4.264080   \n",
      "3    35.742552    13.559204     5.977470    14.126095     4.496507   \n",
      "4   -67.570083    13.948892    16.245660    -6.120800    23.154617   \n",
      "\n",
      "   Component_6  Component_7  Component_8  Component_9  Component_10  ...  \\\n",
      "0    -5.054403   -21.731939    -1.206129     4.192291      0.661723  ...   \n",
      "1    23.187650     8.822139     2.425514     1.760027    -23.063005  ...   \n",
      "2   -10.126593     1.599186     1.175034   -12.996084      3.111158  ...   \n",
      "3     6.005512     9.341738    12.083370     4.714216     -6.263950  ...   \n",
      "4    -5.389026    12.153532   -31.929311     8.861301     -4.605735  ...   \n",
      "\n",
      "   Component_12  Component_13  Component_14  Component_15  Component_16  \\\n",
      "0     -9.566613     -7.261215      5.954220     -0.655474      6.291249   \n",
      "1     -8.883786      8.313670    -11.757878     19.059953     -6.137357   \n",
      "2      0.494015      0.230104     13.048747     -2.409712     -2.400660   \n",
      "3      2.850017      3.112530      4.487942      5.790575      4.736491   \n",
      "4     12.979521     20.403832     -5.081096     -3.753410    -12.356063   \n",
      "\n",
      "   Component_17  Component_18  Component_19  Component_20    Class  \n",
      "0     -9.371277     -3.963480      9.895982     -5.050480     Shea  \n",
      "1      8.479739     -4.256535     -7.779749    -11.126587    Riley  \n",
      "2      6.141464      1.356760     -5.531127      5.967441  Chachra  \n",
      "3     -0.020516     -1.587957      0.424472     -2.077292  Agresti  \n",
      "4     18.889162      4.262404     13.519538     -6.278700    Nigam  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = amazon_train.drop('Class', axis=1)  \n",
    "y = amazon_train['Class']  \n",
    "\n",
    "# number of components\n",
    "n_components = 20\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=111)\n",
    "\n",
    "#fit the model\n",
    "transformed_data = pca.fit_transform(X)\n",
    "\n",
    "pcs_df = pd.DataFrame(transformed_data, columns=[f'Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "#Add target variable back \n",
    "pcs_df['Class'] = y\n",
    "\n",
    "print(pcs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deabbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc7e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7d013885",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m sparse_pca2 \u001b[38;5;241m=\u001b[39m SparsePCA(n_components\u001b[38;5;241m=\u001b[39mn_components, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m111\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#fit the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m transformed_data2 \u001b[38;5;241m=\u001b[39m sparse_pca2\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m     15\u001b[0m transformed_df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(transformed_data2, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_components)])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#Add target variable back \u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_sparse_pca.py:85\u001b[0m, in \u001b[0;36m_BaseSparsePCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     n_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, n_components, random_state)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_sparse_pca.py:307\u001b[0m, in \u001b[0;36mSparsePCA._fit\u001b[0;34m(self, X, n_components, random_state)\u001b[0m\n\u001b[1;32m    305\u001b[0m code_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_init\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    306\u001b[0m dict_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_init\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m code, dictionary, E, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m dict_learning(\n\u001b[1;32m    308\u001b[0m     X\u001b[38;5;241m.\u001b[39mT,\n\u001b[1;32m    309\u001b[0m     n_components,\n\u001b[1;32m    310\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m    311\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m    312\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m    313\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    314\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    315\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    316\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m    317\u001b[0m     code_init\u001b[38;5;241m=\u001b[39mcode_init,\n\u001b[1;32m    318\u001b[0m     dict_init\u001b[38;5;241m=\u001b[39mdict_init,\n\u001b[1;32m    319\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# flip eigenvectors' sign to enforce deterministic output\u001b[39;00m\n\u001b[1;32m    322\u001b[0m code, dictionary \u001b[38;5;241m=\u001b[39m svd_flip(code, dictionary, u_based_decision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_dict_learning.py:685\u001b[0m, in \u001b[0;36mdict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    680\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124m (elapsed time: \u001b[39m\u001b[38;5;132;01m% 3i\u001b[39;00m\u001b[38;5;124ms, \u001b[39m\u001b[38;5;132;01m% 4.1f\u001b[39;00m\u001b[38;5;124mmn, current cost \u001b[39m\u001b[38;5;132;01m% 7.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;241m%\u001b[39m (ii, dt, dt \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m, current_cost)\n\u001b[1;32m    682\u001b[0m     )\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# Update code\u001b[39;00m\n\u001b[0;32m--> 685\u001b[0m code \u001b[38;5;241m=\u001b[39m sparse_encode(\n\u001b[1;32m    686\u001b[0m     X,\n\u001b[1;32m    687\u001b[0m     dictionary,\n\u001b[1;32m    688\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    689\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    690\u001b[0m     init\u001b[38;5;241m=\u001b[39mcode,\n\u001b[1;32m    691\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    692\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive_code,\n\u001b[1;32m    693\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmethod_max_iter,\n\u001b[1;32m    694\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    695\u001b[0m )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;66;03m# Update dictionary in place\u001b[39;00m\n\u001b[1;32m    698\u001b[0m _update_dict(\n\u001b[1;32m    699\u001b[0m     dictionary,\n\u001b[1;32m    700\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    704\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive_dict,\n\u001b[1;32m    705\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_dict_learning.py:378\u001b[0m, in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    375\u001b[0m         regularization \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 378\u001b[0m     code \u001b[38;5;241m=\u001b[39m _sparse_encode(\n\u001b[1;32m    379\u001b[0m         X,\n\u001b[1;32m    380\u001b[0m         dictionary,\n\u001b[1;32m    381\u001b[0m         gram,\n\u001b[1;32m    382\u001b[0m         cov\u001b[38;5;241m=\u001b[39mcov,\n\u001b[1;32m    383\u001b[0m         algorithm\u001b[38;5;241m=\u001b[39malgorithm,\n\u001b[1;32m    384\u001b[0m         regularization\u001b[38;5;241m=\u001b[39mregularization,\n\u001b[1;32m    385\u001b[0m         copy_cov\u001b[38;5;241m=\u001b[39mcopy_cov,\n\u001b[1;32m    386\u001b[0m         init\u001b[38;5;241m=\u001b[39minit,\n\u001b[1;32m    387\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    388\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    389\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    390\u001b[0m         positive\u001b[38;5;241m=\u001b[39mpositive,\n\u001b[1;32m    391\u001b[0m     )\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m code\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Enter parallel code block\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/decomposition/_dict_learning.py:156\u001b[0m, in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Not passing in verbose=max(0, verbose-1) because Lars.fit already\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# corrects the verbosity level.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     lasso_lars \u001b[38;5;241m=\u001b[39m LassoLars(\n\u001b[1;32m    148\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    149\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m     lasso_lars\u001b[38;5;241m.\u001b[39mfit(dictionary\u001b[38;5;241m.\u001b[39mT, X\u001b[38;5;241m.\u001b[39mT, Xy\u001b[38;5;241m=\u001b[39mcov)\n\u001b[1;32m    157\u001b[0m     new_code \u001b[38;5;241m=\u001b[39m lasso_lars\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:1144\u001b[0m, in \u001b[0;36mLars.fit\u001b[0;34m(self, X, y, Xy)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     noise \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39muniform(high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjitter, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[1;32m   1142\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m+\u001b[39m noise\n\u001b[0;32m-> 1144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1145\u001b[0m     X,\n\u001b[1;32m   1146\u001b[0m     y,\n\u001b[1;32m   1147\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m   1148\u001b[0m     alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   1149\u001b[0m     fit_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_path,\n\u001b[1;32m   1150\u001b[0m     normalize\u001b[38;5;241m=\u001b[39m_normalize,\n\u001b[1;32m   1151\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mXy,\n\u001b[1;32m   1152\u001b[0m )\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:1077\u001b[0m, in \u001b[0;36mLars._fit\u001b[0;34m(self, X, y, max_iter, alpha, fit_path, normalize, Xy)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_targets):\n\u001b[1;32m   1076\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m Xy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m Xy[:, k]\n\u001b[0;32m-> 1077\u001b[0m     alphas, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_[k], n_iter_ \u001b[38;5;241m=\u001b[39m lars_path(\n\u001b[1;32m   1078\u001b[0m         X,\n\u001b[1;32m   1079\u001b[0m         y[:, k],\n\u001b[1;32m   1080\u001b[0m         Gram\u001b[38;5;241m=\u001b[39mGram,\n\u001b[1;32m   1081\u001b[0m         Xy\u001b[38;5;241m=\u001b[39mthis_Xy,\n\u001b[1;32m   1082\u001b[0m         copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_X,\n\u001b[1;32m   1083\u001b[0m         copy_Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1084\u001b[0m         alpha_min\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   1085\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   1086\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   1087\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m   1088\u001b[0m         eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m   1089\u001b[0m         return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1090\u001b[0m         return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1091\u001b[0m         positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive,\n\u001b[1;32m   1092\u001b[0m     )\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_\u001b[38;5;241m.\u001b[39mappend(alphas)\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_\u001b[38;5;241m.\u001b[39mappend(n_iter_)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:170\u001b[0m, in \u001b[0;36mlars_path\u001b[0;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX cannot be None if Gram is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse lars_path_gram to avoid passing X and y.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _lars_path_solver(\n\u001b[1;32m    171\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    172\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    173\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mXy,\n\u001b[1;32m    174\u001b[0m     Gram\u001b[38;5;241m=\u001b[39mGram,\n\u001b[1;32m    175\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    177\u001b[0m     alpha_min\u001b[38;5;241m=\u001b[39malpha_min,\n\u001b[1;32m    178\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    179\u001b[0m     copy_X\u001b[38;5;241m=\u001b[39mcopy_X,\n\u001b[1;32m    180\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    181\u001b[0m     copy_Gram\u001b[38;5;241m=\u001b[39mcopy_Gram,\n\u001b[1;32m    182\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    183\u001b[0m     return_path\u001b[38;5;241m=\u001b[39mreturn_path,\n\u001b[1;32m    184\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39mreturn_n_iter,\n\u001b[1;32m    185\u001b[0m     positive\u001b[38;5;241m=\u001b[39mpositive,\n\u001b[1;32m    186\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_least_angle.py:625\u001b[0m, in \u001b[0;36m_lars_path_solver\u001b[0;34m(X, y, Xy, Gram, n_samples, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# Update the cholesky decomposition for the Gram matrix\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_active:\n\u001b[0;32m--> 625\u001b[0m     linalg\u001b[38;5;241m.\u001b[39msolve_triangular(\n\u001b[1;32m    626\u001b[0m         L[:n_active, :n_active],\n\u001b[1;32m    627\u001b[0m         L[n_active, :n_active],\n\u001b[1;32m    628\u001b[0m         trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    629\u001b[0m         lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    630\u001b[0m         overwrite_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mSOLVE_TRIANGULAR_ARGS,\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(L[n_active, :n_active], L[n_active, :n_active])\n\u001b[1;32m    635\u001b[0m diag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mabs(c \u001b[38;5;241m-\u001b[39m v)), eps)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/linalg/_basic.py:265\u001b[0m, in \u001b[0;36msolve_triangular\u001b[0;34m(a, b, trans, lower, unit_diagonal, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    260\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve_triangular\u001b[39m(a, b, trans\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, unit_diagonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    266\u001b[0m                      overwrite_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    Solve the equation `a x = b` for `x`, assuming a is a triangular matrix.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     a1 \u001b[38;5;241m=\u001b[39m _asarray_validated(a, check_finite\u001b[38;5;241m=\u001b[39mcheck_finite)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "X = amazon_train.drop('Class', axis=1)  \n",
    "y = amazon_train['Class']  \n",
    "\n",
    "# number of components\n",
    "n_components = 50\n",
    "\n",
    "sparse_pca2 = SparsePCA(n_components=n_components, random_state=111)\n",
    "\n",
    "#fit the model\n",
    "transformed_data2 = sparse_pca2.fit_transform(X)\n",
    "\n",
    "transformed_df2 = pd.DataFrame(transformed_data2, columns=[f'Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "#Add target variable back \n",
    "transformed_df2['Class'] = y\n",
    "\n",
    "print(transformed_df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e58bc",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a60221a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def compare_methods(X_train, X_valid, y_train, y_valid, classifier_List):\n",
    "    scores = {}\n",
    "\n",
    "    for name, classifier in classifier_List.items():\n",
    "        \n",
    "        # Cross-Validation\n",
    "        cv_scores = cross_val_score(classifier, X_train, y_train, cv=10)\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        predictions = classifier.predict(X_valid)\n",
    "        \n",
    "        # plot Matrix and table \n",
    "        #evaluate_model(y_test, predictions)\n",
    "        \n",
    "        scores[name] = {\n",
    "            \"cross_val_scores\": cv_scores.mean(),\n",
    "            \"test_accuracy\": accuracy_score(y_valid, predictions),\n",
    "            \"precision\": precision_score(y_valid, predictions, average='weighted'),\n",
    "            \"recall\": recall_score(y_valid, predictions, average='weighted'),\n",
    "            \"f1_score\": f1_score(y_valid, predictions, average='weighted')\n",
    "        }\n",
    "        \n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd7580fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component_1</th>\n",
       "      <th>Component_2</th>\n",
       "      <th>Component_3</th>\n",
       "      <th>Component_4</th>\n",
       "      <th>Component_5</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.728565</td>\n",
       "      <td>-2.020127</td>\n",
       "      <td>10.247295</td>\n",
       "      <td>-16.669304</td>\n",
       "      <td>23.554972</td>\n",
       "      <td>Shea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.806106</td>\n",
       "      <td>41.796214</td>\n",
       "      <td>105.134683</td>\n",
       "      <td>-3.771703</td>\n",
       "      <td>1.172454</td>\n",
       "      <td>Riley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-57.908152</td>\n",
       "      <td>25.075320</td>\n",
       "      <td>-15.436117</td>\n",
       "      <td>-9.729442</td>\n",
       "      <td>-23.956176</td>\n",
       "      <td>Chachra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-25.967377</td>\n",
       "      <td>15.462059</td>\n",
       "      <td>-14.965175</td>\n",
       "      <td>-20.436362</td>\n",
       "      <td>7.077724</td>\n",
       "      <td>Agresti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.056590</td>\n",
       "      <td>15.961342</td>\n",
       "      <td>13.649013</td>\n",
       "      <td>30.253384</td>\n",
       "      <td>43.836749</td>\n",
       "      <td>Nigam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Component_1  Component_2  Component_3  Component_4  Component_5    Class\n",
       "0   -18.728565    -2.020127    10.247295   -16.669304    23.554972     Shea\n",
       "1    23.806106    41.796214   105.134683    -3.771703     1.172454    Riley\n",
       "2   -57.908152    25.075320   -15.436117    -9.729442   -23.956176  Chachra\n",
       "3   -25.967377    15.462059   -14.965175   -20.436362     7.077724  Agresti\n",
       "4   -12.056590    15.961342    13.649013    30.253384    43.836749    Nigam"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_pca_df =  transformed_df.copy(deep=True) # Sparse PCA with 5 components\n",
    "pcs_df.head() # PCA with 20 components\n",
    "pca_df = pcs_df.copy(deep=True) # PCA with 50 components\n",
    "sparse_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b93c6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_scores</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.184962</td>\n",
       "      <td>0.154255</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.154255</td>\n",
       "      <td>0.137830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.138628</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.143542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.149467</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.207763</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.144939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.193922</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.095626</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.099525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.122744</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.120907</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.101441</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>0.107942</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>0.084870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.115727</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.115663</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.087153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.035558</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.014149</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.022316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.048152</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.011579</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.049843</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.034607</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.021743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              cross_val_scores  test_accuracy  precision  \\\n",
       "Logistic Regression                   0.184962       0.154255   0.141401   \n",
       "Gaussian Naive Bayes                  0.138628       0.148936   0.223014   \n",
       "Random Forest Classifier              0.149467       0.143617   0.207763   \n",
       "Support Vector Classifier             0.193922       0.127660   0.095626   \n",
       "Decision Tree Classifier              0.122744       0.106383   0.120907   \n",
       "Gradient Boosting Classifier          0.101441       0.090426   0.107942   \n",
       "K-Nearest Neighbors                   0.115727       0.085106   0.115663   \n",
       "Perceptron                            0.035558       0.063830   0.014149   \n",
       "Linear SVC                            0.048152       0.053191   0.011579   \n",
       "AdaBoost Classifier                   0.049843       0.042553   0.034607   \n",
       "\n",
       "                                recall  f1_score  \n",
       "Logistic Regression           0.154255  0.137830  \n",
       "Gaussian Naive Bayes          0.148936  0.143542  \n",
       "Random Forest Classifier      0.143617  0.144939  \n",
       "Support Vector Classifier     0.127660  0.099525  \n",
       "Decision Tree Classifier      0.106383  0.101200  \n",
       "Gradient Boosting Classifier  0.090426  0.084870  \n",
       "K-Nearest Neighbors           0.085106  0.087153  \n",
       "Perceptron                    0.063830  0.022316  \n",
       "Linear SVC                    0.053191  0.018170  \n",
       "AdaBoost Classifier           0.042553  0.021743  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of classifier to be used\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "    \"Linear SVC\": LinearSVC() #,\n",
    "    #\"MLP Classifier\": MLPClassifier() # it dont work for any reason\n",
    "    }\n",
    "\n",
    "\n",
    "X_temp = sparse_pca_df.drop('Class', axis=1)\n",
    "y_temp = sparse_pca_df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "scores_sparse_pca = compare_methods(X_train, X_test, y_train, y_test, classifier_List=classifiers)\n",
    "df_scores = pd.DataFrame(scores_sparse_pca).T # transfrom into df \n",
    "\n",
    "(df_scores.sort_values(by='test_accuracy', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "430e61ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_scores</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.265069</td>\n",
       "      <td>0.271277</td>\n",
       "      <td>0.312981</td>\n",
       "      <td>0.271277</td>\n",
       "      <td>0.269741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>0.332668</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>0.264087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.295363</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.329149</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.229817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.204731</td>\n",
       "      <td>0.175532</td>\n",
       "      <td>0.203738</td>\n",
       "      <td>0.175532</td>\n",
       "      <td>0.149679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.167231</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.205281</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.136339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.201128</td>\n",
       "      <td>0.138298</td>\n",
       "      <td>0.163994</td>\n",
       "      <td>0.138298</td>\n",
       "      <td>0.130347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.147682</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.184207</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.139565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.137030</td>\n",
       "      <td>0.117021</td>\n",
       "      <td>0.159243</td>\n",
       "      <td>0.117021</td>\n",
       "      <td>0.114614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.046272</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.028415</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.011177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              cross_val_scores  test_accuracy  precision  \\\n",
       "Gaussian Naive Bayes                  0.265069       0.271277   0.312981   \n",
       "Logistic Regression                   0.280952       0.260638   0.332668   \n",
       "Random Forest Classifier              0.295363       0.244681   0.329149   \n",
       "Support Vector Classifier             0.204731       0.175532   0.203738   \n",
       "K-Nearest Neighbors                   0.167231       0.143617   0.205281   \n",
       "Gradient Boosting Classifier          0.201128       0.138298   0.163994   \n",
       "Decision Tree Classifier              0.147682       0.127660   0.184207   \n",
       "Linear SVC                            0.137030       0.117021   0.159243   \n",
       "AdaBoost Classifier                   0.046272       0.021277   0.000967   \n",
       "Perceptron                            0.028415       0.021277   0.027898   \n",
       "\n",
       "                                recall  f1_score  \n",
       "Gaussian Naive Bayes          0.271277  0.269741  \n",
       "Logistic Regression           0.260638  0.264087  \n",
       "Random Forest Classifier      0.244681  0.229817  \n",
       "Support Vector Classifier     0.175532  0.149679  \n",
       "K-Nearest Neighbors           0.143617  0.136339  \n",
       "Gradient Boosting Classifier  0.138298  0.130347  \n",
       "Decision Tree Classifier      0.127660  0.139565  \n",
       "Linear SVC                    0.117021  0.114614  \n",
       "AdaBoost Classifier           0.021277  0.001840  \n",
       "Perceptron                    0.021277  0.011177  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = pca_df.drop('Class', axis=1)\n",
    "y_temp = pca_df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "scores_pca = compare_methods(X_train, X_test, y_train, y_test, classifier_List=classifiers)\n",
    "df_scores = pd.DataFrame(scores_pca).T # transfrom into df \n",
    "\n",
    "(df_scores.sort_values(by='test_accuracy', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6bdcaed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Component_1  Component_2  Component_3  Component_4  Component_5  \\\n",
      "0     3.771538     4.252988    -7.817311    10.002531    18.163768   \n",
      "1  -126.142791    48.983971   -52.803615     2.483441    -1.148803   \n",
      "2    77.670115    29.780364     4.925802    -3.529897    -4.264080   \n",
      "3    35.742552    13.559204     5.977470    14.126094     4.496509   \n",
      "4   -67.570083    13.948892    16.245659    -6.120804    23.154644   \n",
      "\n",
      "   Component_6  Component_7  Component_8  Component_9  Component_10  ...  \\\n",
      "0    -5.054241   -21.731941    -1.206880     4.192185      0.661212  ...   \n",
      "1    23.187653     8.822805     2.426974     1.762253    -23.065355  ...   \n",
      "2   -10.126772     1.598913     1.175728   -12.996074      3.109875  ...   \n",
      "3     6.005307     9.341852    12.085811     4.713573     -6.265416  ...   \n",
      "4    -5.388831    12.153428   -31.933780     8.866520     -4.616293  ...   \n",
      "\n",
      "   Component_192  Component_193  Component_194  Component_195  Component_196  \\\n",
      "0      -4.452643       0.165449      -2.302625       1.191681       2.134585   \n",
      "1       1.401190      -1.412729       2.513208      -2.467875      -4.932912   \n",
      "2       4.835230      -1.600301      -3.309910      -0.474858      -5.491627   \n",
      "3       0.621183       0.682410      -3.648553       0.118312      -2.332145   \n",
      "4       3.574673       2.838867       0.517342       2.055990      -0.153729   \n",
      "\n",
      "   Component_197  Component_198  Component_199  Component_200    Class  \n",
      "0       1.719298       3.399169       1.298525       3.613730     Shea  \n",
      "1      -2.303766      -4.798282       1.060654      -4.270287    Riley  \n",
      "2       0.315166      -0.425832      -2.163800      -1.299529  Chachra  \n",
      "3       2.268915       1.467589       3.865816      -0.353180  Agresti  \n",
      "4      -3.235028       1.306931      -4.494896      -4.497600    Nigam  \n",
      "\n",
      "[5 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = amazon_train.drop('Class', axis=1)  \n",
    "y = amazon_train['Class']  \n",
    "\n",
    "# number of components\n",
    "n_components = 200\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=111)\n",
    "\n",
    "#fit the model\n",
    "transformed_data = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(transformed_data, columns=[f'Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "#Add target variable back \n",
    "pca_df['Class'] = y\n",
    "\n",
    "print(pca_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "737fd080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_scores</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.524969</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.669238</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.587147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.348904</td>\n",
       "      <td>0.356383</td>\n",
       "      <td>0.452054</td>\n",
       "      <td>0.356383</td>\n",
       "      <td>0.372779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.233020</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.323401</td>\n",
       "      <td>0.244681</td>\n",
       "      <td>0.240203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.243860</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.227830</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.193551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.259806</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.431099</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.262445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.233051</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.213318</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.159638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.172682</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.249016</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.139288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.122964</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>0.141495</td>\n",
       "      <td>0.090426</td>\n",
       "      <td>0.086363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.101566</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.099702</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.076901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.039160</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              cross_val_scores  test_accuracy  precision  \\\n",
       "Logistic Regression                   0.524969       0.590426   0.669238   \n",
       "Linear SVC                            0.348904       0.356383   0.452054   \n",
       "Random Forest Classifier              0.233020       0.244681   0.323401   \n",
       "Support Vector Classifier             0.243860       0.234043   0.227830   \n",
       "Gaussian Naive Bayes                  0.259806       0.234043   0.431099   \n",
       "K-Nearest Neighbors                   0.233051       0.170213   0.213318   \n",
       "Perceptron                            0.172682       0.143617   0.249016   \n",
       "Gradient Boosting Classifier          0.122964       0.090426   0.141495   \n",
       "Decision Tree Classifier              0.101566       0.074468   0.099702   \n",
       "AdaBoost Classifier                   0.039160       0.021277   0.000980   \n",
       "\n",
       "                                recall  f1_score  \n",
       "Logistic Regression           0.590426  0.587147  \n",
       "Linear SVC                    0.356383  0.372779  \n",
       "Random Forest Classifier      0.244681  0.240203  \n",
       "Support Vector Classifier     0.234043  0.193551  \n",
       "Gaussian Naive Bayes          0.234043  0.262445  \n",
       "K-Nearest Neighbors           0.170213  0.159638  \n",
       "Perceptron                    0.143617  0.139288  \n",
       "Gradient Boosting Classifier  0.090426  0.086363  \n",
       "Decision Tree Classifier      0.074468  0.076901  \n",
       "AdaBoost Classifier           0.021277  0.001863  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = pca_df.drop('Class', axis=1)\n",
    "y_temp = pca_df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "scores_pca = compare_methods(X_train, X_test, y_train, y_test, classifier_List=classifiers)\n",
    "df_scores = pd.DataFrame(scores_pca).T # transfrom into df \n",
    "\n",
    "(df_scores.sort_values(by='test_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "460906b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Component_1  Component_2  Component_3  Component_4  Component_5  \\\n",
      "0     3.771538     4.252988    -7.817311    10.002531    18.163768   \n",
      "1  -126.142791    48.983971   -52.803615     2.483441    -1.148803   \n",
      "2    77.670115    29.780364     4.925802    -3.529897    -4.264080   \n",
      "3    35.742552    13.559204     5.977470    14.126094     4.496509   \n",
      "4   -67.570083    13.948892    16.245659    -6.120804    23.154644   \n",
      "\n",
      "   Component_6  Component_7  Component_8  Component_9  Component_10  ...  \\\n",
      "0    -5.054241   -21.731941    -1.206880     4.192185      0.661212  ...   \n",
      "1    23.187653     8.822805     2.426974     1.762253    -23.065355  ...   \n",
      "2   -10.126772     1.598913     1.175728   -12.996074      3.109875  ...   \n",
      "3     6.005307     9.341852    12.085811     4.713573     -6.265416  ...   \n",
      "4    -5.388831    12.153428   -31.933780     8.866520     -4.616293  ...   \n",
      "\n",
      "   Component_192  Component_193  Component_194  Component_195  Component_196  \\\n",
      "0      -4.452643       0.165449      -2.302625       1.191681       2.134585   \n",
      "1       1.401190      -1.412729       2.513208      -2.467875      -4.932912   \n",
      "2       4.835230      -1.600301      -3.309910      -0.474858      -5.491627   \n",
      "3       0.621183       0.682410      -3.648553       0.118312      -2.332145   \n",
      "4       3.574673       2.838867       0.517342       2.055990      -0.153729   \n",
      "\n",
      "   Component_197  Component_198  Component_199  Component_200    Class  \n",
      "0       1.719298       3.399169       1.298525       3.613730     Shea  \n",
      "1      -2.303766      -4.798282       1.060654      -4.270287    Riley  \n",
      "2       0.315166      -0.425832      -2.163800      -1.299529  Chachra  \n",
      "3       2.268915       1.467589       3.865816      -0.353180  Agresti  \n",
      "4      -3.235028       1.306931      -4.494896      -4.497600    Nigam  \n",
      "\n",
      "[5 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = amazon_train.drop('Class', axis=1)  \n",
    "y = amazon_train['Class']  \n",
    "\n",
    "# number of components\n",
    "n_components = 200\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=111)\n",
    "\n",
    "#fit the model\n",
    "transformed_data = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(transformed_data, columns=[f'Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "#Add target variable back \n",
    "pca_df['Class'] = y\n",
    "\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "81a2d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_scores</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.524969</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.669238</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.587147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.361247</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.445213</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.356216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.243860</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.227830</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.193551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.259806</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.431099</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.262445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.245457</td>\n",
       "      <td>0.218085</td>\n",
       "      <td>0.210908</td>\n",
       "      <td>0.218085</td>\n",
       "      <td>0.187855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.233051</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.213318</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.159638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.172682</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.249016</td>\n",
       "      <td>0.143617</td>\n",
       "      <td>0.139288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.106830</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.133618</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.108091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.086880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.042732</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              cross_val_scores  test_accuracy  precision  \\\n",
       "Logistic Regression                   0.524969       0.590426   0.669238   \n",
       "Linear SVC                            0.361247       0.351064   0.445213   \n",
       "Support Vector Classifier             0.243860       0.234043   0.227830   \n",
       "Gaussian Naive Bayes                  0.259806       0.234043   0.431099   \n",
       "Random Forest Classifier              0.245457       0.218085   0.210908   \n",
       "K-Nearest Neighbors                   0.233051       0.170213   0.213318   \n",
       "Perceptron                            0.172682       0.143617   0.249016   \n",
       "Decision Tree Classifier              0.106830       0.106383   0.133618   \n",
       "Gradient Boosting Classifier          0.115789       0.095745   0.137337   \n",
       "AdaBoost Classifier                   0.042732       0.021277   0.000980   \n",
       "\n",
       "                                recall  f1_score  \n",
       "Logistic Regression           0.590426  0.587147  \n",
       "Linear SVC                    0.351064  0.356216  \n",
       "Support Vector Classifier     0.234043  0.193551  \n",
       "Gaussian Naive Bayes          0.234043  0.262445  \n",
       "Random Forest Classifier      0.218085  0.187855  \n",
       "K-Nearest Neighbors           0.170213  0.159638  \n",
       "Perceptron                    0.143617  0.139288  \n",
       "Decision Tree Classifier      0.106383  0.108091  \n",
       "Gradient Boosting Classifier  0.095745  0.086880  \n",
       "AdaBoost Classifier           0.021277  0.001863  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = pca_df.drop('Class', axis=1)\n",
    "y_temp = pca_df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "scores_pca = compare_methods(X_train, X_test, y_train, y_test, classifier_List=classifiers)\n",
    "df_scores = pd.DataFrame(scores_pca).T # transfrom into df \n",
    "\n",
    "(df_scores.sort_values(by='test_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "df05779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Component_1  Component_2  Component_3  Component_4  Component_5  \\\n",
      "0   -12.991579    -4.257283    15.680523    -8.111694    -7.805619   \n",
      "1    18.103297   -18.706610    40.989118    43.231153    -1.085149   \n",
      "2   -23.752729   -17.409279    -5.194998   -12.997958    -0.690276   \n",
      "3    11.970953     0.030825   -10.743086    -9.504986    -3.911179   \n",
      "4    11.069263    16.293165     8.459849    28.428720    40.368975   \n",
      "\n",
      "   Component_6  Component_7  Component_8  Component_9  Component_10  ...  \\\n",
      "0    -5.633683    19.193301    -1.674130     1.357969    -14.608687  ...   \n",
      "1    -9.737684    -4.915006    -9.363754     4.696176      5.925235  ...   \n",
      "2    -9.782083    -2.254201    17.953774   -11.977309     -6.769396  ...   \n",
      "3    -1.587141    -8.112800     2.527937    -9.756407    -15.016664  ...   \n",
      "4   -12.404117    13.315512     1.202819    -6.712590     -0.422797  ...   \n",
      "\n",
      "   Component_42  Component_43  Component_44  Component_45  Component_46  \\\n",
      "0      1.244770      1.942826      4.552617      2.824398     -5.482684   \n",
      "1     -4.007460      4.288216      7.812362      6.450723     -8.969875   \n",
      "2     -4.242422     -2.697798      6.033548      0.429396     -7.652775   \n",
      "3      4.111492      7.858255      2.154510     -0.697664     -5.426059   \n",
      "4     -8.095995     -3.937112     11.765518     -5.987427     -5.563081   \n",
      "\n",
      "   Component_47  Component_48  Component_49  Component_50    Class  \n",
      "0      8.282199     -3.772646      0.033308      2.354682     Shea  \n",
      "1     -0.610531      1.153235      2.973469    -10.014408    Riley  \n",
      "2     -1.865797     -6.331201     22.387980     -9.418355  Chachra  \n",
      "3      2.191112     15.960141      8.785663     -8.150639  Agresti  \n",
      "4      4.130618     -7.023822      2.035729    -21.184858    Nigam  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "X = amazon_train.drop('Class', axis=1)  \n",
    "y = amazon_train['Class']  \n",
    "\n",
    "# number of components\n",
    "n_components = 50\n",
    "\n",
    "sparse_pca = SparsePCA(n_components=n_components, random_state=111)\n",
    "\n",
    "#fit the model\n",
    "transformed_data = sparse_pca.fit_transform(X)\n",
    "\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=[f'Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "#Add target variable back \n",
    "transformed_df['Class'] = y\n",
    "\n",
    "print(transformed_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f59faee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_scores</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.366573</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.423415</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.397765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.389662</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.525785</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.420397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>0.352381</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.441861</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.395008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>0.375313</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.455273</td>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.385839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVC</th>\n",
       "      <td>0.355702</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.397880</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.341585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>0.245583</td>\n",
       "      <td>0.239362</td>\n",
       "      <td>0.312517</td>\n",
       "      <td>0.239362</td>\n",
       "      <td>0.233557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>0.197682</td>\n",
       "      <td>0.175532</td>\n",
       "      <td>0.249335</td>\n",
       "      <td>0.175532</td>\n",
       "      <td>0.174633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.135119</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.178242</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.140388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.115695</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.108865</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.088838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost Classifier</th>\n",
       "      <td>0.053383</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.021339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              cross_val_scores  test_accuracy  precision  \\\n",
       "Random Forest Classifier              0.366573       0.430851   0.423415   \n",
       "Logistic Regression                   0.389662       0.414894   0.525785   \n",
       "Gaussian Naive Bayes                  0.352381       0.404255   0.441861   \n",
       "Support Vector Classifier             0.375313       0.398936   0.455273   \n",
       "Linear SVC                            0.355702       0.361702   0.397880   \n",
       "K-Nearest Neighbors                   0.245583       0.239362   0.312517   \n",
       "Gradient Boosting Classifier          0.197682       0.175532   0.249335   \n",
       "Decision Tree Classifier              0.135119       0.148936   0.178242   \n",
       "Perceptron                            0.115695       0.095745   0.108865   \n",
       "AdaBoost Classifier                   0.053383       0.042553   0.016318   \n",
       "\n",
       "                                recall  f1_score  \n",
       "Random Forest Classifier      0.430851  0.397765  \n",
       "Logistic Regression           0.414894  0.420397  \n",
       "Gaussian Naive Bayes          0.404255  0.395008  \n",
       "Support Vector Classifier     0.398936  0.385839  \n",
       "Linear SVC                    0.361702  0.341585  \n",
       "K-Nearest Neighbors           0.239362  0.233557  \n",
       "Gradient Boosting Classifier  0.175532  0.174633  \n",
       "Decision Tree Classifier      0.148936  0.140388  \n",
       "Perceptron                    0.095745  0.088838  \n",
       "AdaBoost Classifier           0.042553  0.021339  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = transformed_df.drop('Class', axis=1)\n",
    "y_temp = transformed_df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "scores_pca = compare_methods(X_train, X_test, y_train, y_test, classifier_List=classifiers)\n",
    "df_scores = pd.DataFrame(scores_pca).T # transfrom into df \n",
    "\n",
    "(df_scores.sort_values(by='test_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9df56625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Component_1  Component_2  Component_3  Component_4  Component_5  \\\n",
      "0     3.771538     4.252988    -7.817311    10.002531    18.163768   \n",
      "1  -126.142791    48.983971   -52.803615     2.483441    -1.148802   \n",
      "2    77.670115    29.780364     4.925802    -3.529897    -4.264080   \n",
      "3    35.742552    13.559204     5.977469    14.126094     4.496508   \n",
      "4   -67.570083    13.948892    16.245659    -6.120803    23.154643   \n",
      "\n",
      "   Component_6  Component_7  Component_8  Component_9  Component_10  ...  \\\n",
      "0    -5.054240   -21.731941    -1.206883     4.192184      0.661214  ...   \n",
      "1    23.187654     8.822804     2.426979     1.762250    -23.065362  ...   \n",
      "2   -10.126772     1.598912     1.175724   -12.996069      3.109880  ...   \n",
      "3     6.005306     9.341849    12.085810     4.713578     -6.265419  ...   \n",
      "4    -5.388832    12.153424   -31.933780     8.866520     -4.616303  ...   \n",
      "\n",
      "   Component_392  Component_393  Component_394  Component_395  Component_396  \\\n",
      "0      -0.582812      -2.406164       0.274703      -3.097288      -0.300301   \n",
      "1      -1.138886       0.318414       0.622651       1.513345      -1.496524   \n",
      "2       1.715084      -0.994214       0.377475      -0.432089      -2.559532   \n",
      "3       0.222832       2.577166       1.987056       1.445622       2.316273   \n",
      "4      -1.075245       1.340970      -2.150526       1.172863      -0.828963   \n",
      "\n",
      "   Component_397  Component_398  Component_399  Component_400    Class  \n",
      "0      -0.206972      -0.964583      -1.656647       1.199954     Shea  \n",
      "1       0.311248       0.526165       0.467721      -0.887135    Riley  \n",
      "2       2.764573      -2.092852       0.816955      -0.106061  Chachra  \n",
      "3      -0.035869      -1.130759       2.011821       3.108706  Agresti  \n",
      "4       0.815913      -2.364002       1.493436       0.369126    Nigam  \n",
      "\n",
      "[5 rows x 401 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = amazon_train.drop('Class', axis=1)  \n",
    "y = amazon_train['Class']  \n",
    "\n",
    "# number of components\n",
    "n_components = 400\n",
    "\n",
    "pca = PCA(n_components=n_components, random_state=111)\n",
    "\n",
    "#fit the model\n",
    "transformed_data = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(transformed_data, columns=[f'Component_{i+1}' for i in range(n_components)])\n",
    "\n",
    "#Add target variable back \n",
    "pca_df['Class'] = y\n",
    "\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eb247e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{LogisticRegression(): {'test_accuracy': 0.6063829787234043, 'precision': 0.6914197061803444, 'recall': 0.6063829787234043, 'f1_score': 0.6067590801633356}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 3, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 7]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of classifier to be used\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "    }\n",
    "\n",
    "\n",
    "X_temp = pca_df.drop('Class', axis=1)\n",
    "y_temp = pca_df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "scores = compare_methods(X_train, X_test, y_train, y_test, classifier_List=classifiers)\n",
    "df_scores = pd.DataFrame(scores).T # transfrom into df \n",
    "df_scores\n",
    "\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr_classifier.predict(X_test)\n",
    "        \n",
    "scores = {}\n",
    "\n",
    "     \n",
    "scores[lr_classifier] = {\n",
    "\"test_accuracy\": accuracy_score(y_test, predictions),\n",
    "\"precision\": precision_score(y_test, predictions, average='weighted'),\n",
    "\"recall\": recall_score(y_test, predictions, average='weighted'),\n",
    "\"f1_score\": f1_score(y_test, predictions, average='weighted')\n",
    "}\n",
    "\n",
    "print(scores)\n",
    "\n",
    "\n",
    "# Create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(y_test, predictions)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e054ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
